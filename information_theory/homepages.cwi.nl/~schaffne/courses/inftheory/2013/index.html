<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>




<head>
    <meta content="text/html; charset=ISO-8859-1" http-equiv="content-type">

    <title>Homepage of Christian Schaffner</title>
    <link rel="stylesheet" href="/~schaffne/static/css/mystyle.css" type="text/css">
    <link rel="shortcut icon" href="/~schaffne/static/img/favicon.ico" type="image/x-icon">
</head>

<body>
<div id="header">
    <table>
        <tr>
            <td width="100"><a href="http://www.uva.nl/"><img src="/~schaffne/static/img/UvA.png" height="90" border="0"
                                                              alt="UvA"></a></td>
            <td>
                <h2>Personal homepage of Christian Schaffner</h2>
            </td>
            <td width="90"><a href="http://www.cwi.nl/"><img src="/~schaffne/static/img/CWILogo.png" height="70"
                                                             border="0" alt="CWI"></a></td>
            <td width="20">&nbsp;</td>	    
            <td width="90"><a href="http://www.qusoft.org/"><img src="/~schaffne/static/img/qusoft_logo.png" height="40"
                                                             border="0" alt="QuSoft"></a></td>
        </tr>
    </table>
</div>

<div id="menu">
    <ul>
        <li><a href="/~schaffne/index.php">Home</a></li>
<li><a href="/~schaffne/contact.php">Contact</a></li>
<li><a href="/~schaffne/publications.php">Publications</a></li>
<li><a href="/~schaffne/talks.php">Talks</a></li>
<li><a href="/~schaffne/cv.php">CV</a></li>
<li><a href="/~schaffne/positionbasedqcrypto.php">Position-Based<br> Quantum Crypto</a></li>
<li><a href="/~schaffne/courses/index.php">Teaching</a></li>
<li><a href="/~schaffne/courses/crypto/2015/">Crypto 2016</a></li>

    </ul>
</div>

<div id="content">


<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>

<h2>Information Theory</h2>
<div id="topbox">
  <div class="subbox">
    <a href="http://www.uva.nl">University
    of Amsterdam course</a>, Spring 2014<br>
    <a href="http://www.illc.uva.nl/MScLogic/">Master of Logic</a>
    <div id="lecturer">
      Lecturer: <a href="http://homepages.cwi.nl/%7Eschaffne">Christian
        Schaffner</a> (<a href="http://www.uva.nl/">UvA</a> / <a
      href="http://homepages.cwi.nl/%7Eschaffne/contact.php">email</a>)
      <br>
      Teaching assistant: <a
      href="http://www.illc.uva.nl/People/show_person.php?Person_id=Hoang+C.">Cuong
      Hoang</a> (<a href="mailto:hoangcuong2011@gmail.com">hoangcuong2011 at gmail.com</a>)
    </div>
  </div>

<!--   <div class="subbox"> -->
<!--     30 Dec: Malvin (and two friends) solved the crypto challenge and -->
<!--     won the price! Congratulations!<br> -->
<!--     19 Dec: The final presentations and the course are over! You will -->
<!--     hear from us about your grades soon. Check out the section about -->
<!--     "life after Intro to Modern Crypto" below.<br> -->
<!--     16 Dec: The <a -->
<!--     href="http://www.bbc.co.uk/news/uk-20164591">pigeon</a>-<a -->
<!--     href="http://www.bbc.co.uk/news/uk-20456782">challenge</a> has -->
<!--     apparantly been <a -->
<!--     href="http://www.bbc.co.uk/news/uk-20749632">solved</a>! The -->
<!--     crypto challenge of this course is still open. You have time until -->
<!--     the end of January 2013 to claim the price!<br> -->
<!--     21 Nov: werkcolleges on Wednesday will now be from 11-13 instead -->
<!--     of 9-11<br> -->
<!--     19 Nov: <a href="papers.html">topics and procedure</a> for final exam online<br> -->
<!--     15 Nov: see <a href="http://marc-stevens.nl/research/mastermath/msth_proposal.pdf">here</a> for an advertisement for Mark Steven's Master student project<br> -->
<!--     13 Nov: second hint for crypto challenge released (see below)<br> -->
<!--     7 Nov: <a href="#exercises">where</a> to hand in your exercises<br> -->
<!--     6 Nov: Hint for crypto challenge released: "Many-Time Pad"<br> -->
<!--     30 October: <a href="challenge.pdf">crypto challenge</a> -->
<!--     online<br> -->
<!--   </div> -->

<!--   <div class="subbox"> -->
<!--     See <a href="2011/index.html">here</a> for the 2011 edition of -->
<!--     this course -->
<!--   </div> -->
<!-- </div> <\!-- #topbox -\-> -->

<h3>Content of the course</h3>
<a target="_blank" href="http://en.wikipedia.org/wiki/Information_theory">Information theory</a> was developed by Claude E. Shannon in the 1950s to investigate the fundamental limits on signal-processing operations such as compressing data and on reliably storing and communicating data. These tasks have turned out to be fundamental for all of computer science.
<p>
In this course, we quickly review the basics of probability theory and introduce concepts such as (conditional) Shannon entropy, mutual information and Renyi entropy. Then, we prove Shannon's theorems about data compression and channel coding. Later in the course, we also cover some aspects of information-theoretic security such as the concept of randomness extraction and privacy amplification.

<h3>Intended Learning Outcomes</h3>
Now, at the end of the course, you are able to
<ul>
<li>Define Shannon entropy and Mutual Information and compute these quantities on examples.</li>
<li>Work with joint discrete random variables (conditioning, Bayes' rule)</li>
<li>Define basic discrete probability distributions (Bernoulli, Binomial, Geometric) and compute their expected value and variance</li>
<li>State Jensen's inequality for convex and concave functions and use it in proofs</li>
<li>Use entropy diagrams to read off and find new relations between entropic quantities</li>
<li>Prove Shannon's theorem about perfectly secure encryption (e.g. by using an entropy diagram)</li>
<li>Define typical and jointly typical sets, prove properties about their size and probability mass and know how they are used in source coding and channel coding</li>
<li>Use Kraft's inequality e.g. to check if a prefix-free code exists for given codeword lengths</li>
<li>Compute a d-ary Huffman code</li>
<li>Describe how much a given source can be compressed and give a way to do it</li>
<li>Prove properties about Arithmetic Codes</li>
<li>Find the confusability graph of a given channel, and find channels for a given confusability graph</li>
<li>Compute the independence number and (zero-error) Shannon capacity of a given confusability graph</li>
<li>Compute the capacity and maximizing input distribution of a given channel</li>
<li>Define basic channels (binary symmetric, erasure channel)</li>
<li>State Shannon's noisy channel-coding theorem and and understand the key ingredients of the proof</li>
<li>Grasp definitions of types of entropy different than Shannon entropy</li>

<!-- <li>select, summarize and defend a more advanced topic in information theory</li>
 <li>relate and compare that advanced topic with material in the course </li> 
 <li>State Hoeffding's inequality and recognize situations where it can be employed</li>
<li>Grasp the purpose of privacy amplification</li>
<li>Check whether a given function family is two-universal</li> -->


</ul>


<h3>Course website</h3>
Updated information about the course can be found on <a href="http://homepages.cwi.nl/~schaffne/courses/inftheory/2014/">http://homepages.cwi.nl/~schaffne/courses/inftheory/2014/</a>

<h3>Study Material</h3>
The material will be presented in black-boards lectures. The following are good references:
<ul>
<li>[CF] Ronald Cramer, Serge Fehr: <a href="notes/CramerFehr.pdf">The
  Mathematical Theory of Information, and Applications</a>, lecture notes, Version 2.0</li>
<li>[CT] Thomas M. Cover, Joy A. Thomas. <a target="blank" href="http://onlinelibrary.wiley.com/book/10.1002/0471200611">Elements of information theory</a>, 2nd Edition. New York: Wiley-Interscience, 2006. ISBN 0-471-24195-4. 
<li>[MacKay] David J. C. MacKay. <a target="blank" href="http://www.inference.phy.cam.ac.uk/mackay/itila/book.html">Information Theory, Inference, and Learning Algorithms</a>. Cambridge: Cambridge University Press, 2003. ISBN 0-521-64298-1
</ul>


<h3>Lectures and Exercise sessions (2 x 45min each)</h3>
please check <a
href="https://datanose.nl/#course[22718]">Datanose</a> for the
definite times and locations.<br>

<a name="location"></a>
<b>Lectures (Hoorcollege)</b><br>
Times: Tuesdays, 11-13, location: Science Park G0.05<br>
Thursdays, 11-13, location: check <a
href="https://datanose.nl/#course[22718]">Datanose</a><br>
starting 4 February 2013<br>
<br>

<b>Exercises (Werkcollege)</b><br>
Time: Fridays 9-11, location: check <a
href="https://datanose.nl/#course[22718]">Datanose</a><br>
first exercises: 7 February 2013<br>
<br>


<h3>Homework, exam, and grading</h3>

This is a 6 ECTS course, which comes to roughly 20 hours of work per
week.

<p> There will be homework exercises every week
to be handed in one week later.  The answers should be in English. Feel free to use LaTeX, here is a <a href="HW-template.tex">template</a> to get you started, but readable handwritten solutions
are fine, too. Cooperation while solving the exercises is allowed and
encouraged, but everyone has to hand in their own solution set in
their own words. <a name="exercises"></a>

<p> <a name="exam"></a>There will be a final written exam on Friday, March 28, 2014, from 9:00-12:00 in SP, G2.02. The exam is open-book, meaning that you can bring the study material [CF], [CT],
[MacKay] mentioned above as well as any notes you made, but no electronic devices are allowed.

<!-- or the final exam will consist of student presentations
about slightly more advanced topics connected to the course. The detailed
 procedure and list of topics can be found <a href="papers.html">here</a>.</b> -->

<p> The final grade for the course consists by 1/2 of the average homework grade (ignoring the worst grade) and 1/2 of the grade obtained at the final exam.

<h3>Preliminary course schedule Spring 2014</h3>
<table id="schedule">
  <tr>
    <td>Tue, 4 Feb 2014</td>
    <td>
      <p>Overview of the course, Probability Theory</p>
      <p>Section 2.1 of [CF]</p>
      <a href="InfTheory_L1.pdf">Slides</a>
    </td>
  </tr>
  <tr>
    <td>Thu, 6 Feb 2014</td>
    <td>
      <p>Shannon Entropy, Jensen's inequality, Properties of Shannon entropy</p>
      <p>Sections 3.1-3.3 of [CF]</p>
      <a href="InfTheory_L2.pdf">Slides</a>
      <a href="inf1314-ex1.pdf">Homework #1</a> <b>(updated)</b>&nbsp;
      <p>6 Feb 14: There was a typo in the definition of the random variable Z in homework exercise 4, it is corrected now.</p>
    </td>
  </tr>
  <tr>									   
    <td>Tue, 11 Feb 2014</td>
    <td>
      <p>Chain Rule, Mutual Information, Entropy Diagrams, Markov Chains</p>
      <p>Sections 3.3, 3.4 of [CF], Sections 2.5, 2.8 of [CT]</p>
    </td>
  </tr>
  <tr>
    <td>Thu, 13 Feb 2014</td>
    <td>
      <p>Data-Processing Inequality, Sufficient Statistics,Fano's inequality, Perfectly Secure Encryption: One-time pad</p>
      <p>Sections 2.8-2.10 of [CT], Section 4 of [CF]</p>
      <a href="inf1314-ex2.pdf">Homework #2 (updated)</a>&nbsp;
      <a href="HW-template.tex">Homework Latex Template</a> <b>(updated)</b>&nbsp;
    </td>
  </tr>
  <tr>
    <td>Tue, 18 Feb 2014</td>
    <td>
      <p>Perfectly Secure Encryption: Shannon's theorem. Data compression / Source coding, Asymptotic Equipartition Property</p>
      <p>Section 4 of [CF], Section 3.1 of [CT]</p>
      <a target="_blank" href="https://docs.google.com/spreadsheet/ccc?key=0Am3l5NEdfBL3dGYyMjBvSUltYVExQjlZRkZGcThOS3c&usp=sharing">Entropy of Alice in Wonderland</a>&nbsp; <a target="_blank" href="http://en.webhex.net/">Hex Editor with statistics</a>&nbsp;
      <a href="InfTheory_L5.pdf">Slides</a>
    </td>
  </tr>
  <tr>
    <td>Thu, 20 Feb 2014</td>
    <td>
      <p>Data Compression: Typical set, Source-coding Theorem, high-probability set, symbol codes</p>
      <p>Section 3.2+3.3 of [CT]</p>
      <a href="inf1314-ex3.pdf">Homework #3</a>&nbsp;
      <a href="ProbTable-ex3.pdf">Table for #3, Exercise 3</a>&nbsp;
      <a href="Template_entropy_diagrams.tex">Entropy Diagram Latex Template</a> <b>(thanks to Yfke!)</b>&nbsp;<br>
      <b>25 Feb 14: Added PDF file of the probability table for ex 3.</b>
    </td>
  </tr>
  <tr>
    <td>Tue, 25 Feb 2014</td>
    <td>
      <p>Data Compression: symbol codes, properties, source-coding theorem reloaded, Kraft's inequality, Huffman codes</p>
      <p>Section 5 of [CF], Chapter 5 of [CT], Chapter 5 of [MacKay]</p>
      <a href="InfTheory_L7.pdf">Slides</a>
    </td>
  </tr>
  <tr>
    <td>Thu, 27 Feb 2014</td>
    <td>
      <p>Optimality of Huffman Codes, Arithmetic Codes</p>
      <p>Section 5.4+5.5 of [CF], Section 6.2 of [MacKay]</p>
      <a href="inf1314-ex4.pdf">Homework #4</a>&nbsp;
    </td>
  </tr>
  <tr>
    <td>Tue, 4 Mar 2014</td>
    <td>
      <p>Guest lecture by Teresa Piovesan</p>
      <p>Zero-error information theory</p>
      <p>Pages 4+5 of this <a href="http://alon.ucsd.edu/papers/zer_err_it.ps">survey paper</a></p>
    </td>
  </tr>
  <tr>
    <td>Thu, 6 Mar 2014</td>
    <td>
      <p>Guest lecture by Teresa Piovesan</p>
      <p>Zero-error information theory</p>
	<a href="inf1314-ex5v2.pdf">Homework #5</a> <b>(updated, thanks to Teresa!)</b>&nbsp;<br> 
        Clarification added in Exercise 2(f). &nbsp;
    </td>
  </tr>
  <tr>
    <td>Tue, 11 Mar 2014</td>
    <td>
      <p>Noisy-channel coding: capacity, set-up and proof of converse</p>
      <p>Sections 7.1, 7.4, 7.5, 7.9, 7.12 of [CT]</p>
    </td>
  </tr>
  <tr>
    <td>Thu, 13 Mar 2014</td>
    <td>
      <p>Shannon's theorem about noisy-channel coding</p>
      <p>Sections 7.6, 7.7 of [CT], Chapter 10 of [MacKay]</p>
      <a href="InfTheory_L12.pdf">Slides</a> &nbsp; 
      <a href="inf1314-ex6.pdf">Homework #6</a> 
    </td>
  </tr>
  <tr>
    <td>Tue, 18 Mar 2014</td>
    <td>
      <p>Source-channel Separation, Error-correcting codes</p>
      <p>Section 7.13 of [CT], Chapter 1 of [MacKay]</p>
      <a href="InfTheory_L13.pdf">Slides</a> &nbsp;       
    </td>
  </tr>
  <tr>
    <td>Thu, 20 Mar 2014</td>
    <td>
      <p>No more lecture, but exercise session instead of Fri, 21 March</p>
      <a href="inf1314-ex7.pdf">Homework #7</a> 
    </td>
  </tr>
  <tr>
    <td>Fri, 21 Mar 2014</td>
    <td>
      <p><b>No Exercise Session</b></p>
    </td>
  </tr>
  <tr>
    <td>Tue, 25 Mar 2014</td>
    <td>
      <p>No Lecture (exam week)</p>
    </td>
  </tr>
  <tr>
    <td>Thu, 27 Mar 2014</td>
    <td>
      <p>No Lecture (exam week)</p>
    </td>
  </tr>
  <tr>
    <td>Fri, 28 Mar 2014</td>
    <td><p><b>Final Written exam</b></p>
    9:00-12:00 in SP, G2.02
    </td>
  </tr>
</table>

</div>

<div id="footer">
Last update: 9 May 2016. <small><a href="http://www.cwi.nl/disclaimer.html">CWI DISCLAIMER</a></small>
<br>

<!-- Start of StatCounter Code -->
<script type="text/javascript" language="javascript">
<!-- 
var sc_project=1639480; 
var sc_invisible=1; 
var sc_partition=15; 
var sc_security="19c07acf"; 
//-->
</script>

<script type="text/javascript" language="javascript" src="http://www.statcounter.com/counter/counter.js"></script><noscript><a href="http://statcounter.com/" target="_blank"><img  src="http://c16.statcounter.com/counter.php?sc_project=1639480&amp;java=0&amp;security=19c07acf&amp;invisible=1" alt="website page counter" border="0"></a> </noscript>
<!-- End of StatCounter Code -->

<script type="text/javascript">

  var _gaq = _gaq || [];
_gaq.push(['_setAccount', 'UA-23222525-1']);
_gaq.push(['_trackPageview']);

(function() {
  var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
  ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
  var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})();

</script>

</div>

</body>
</html>
